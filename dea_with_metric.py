import os
import sys
from dotenv import load_dotenv
from contextlib import redirect_stdout
import re 

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1] Import Metric ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á ---
try:
    from metrics.ExtractionRate import ExtractionRate
except ImportError:
    print("Error: Could not import 'ExtractionRate'. Make sure 'metrics/ExtractionRate.py' exists.")
    sys.exit(1)

OUTPUT_DIR = "output/dea"
BASE_FILENAME = "dea_output"
EXTENSION = ".txt"

os.makedirs(OUTPUT_DIR, exist_ok=True)
existing_files = os.listdir(OUTPUT_DIR)
next_index = 1

pattern = re.compile(rf"^{BASE_FILENAME}_(\d+){EXTENSION}$")

for filename in existing_files:
    match = pattern.match(filename)
    if match:
        current_index = int(match.group(1))
        if current_index >= next_index:
            next_index = current_index + 1

OUTPUT_FILENAME = f"{BASE_FILENAME}_{next_index}{EXTENSION}"
OUTPUT_PATH = os.path.join(OUTPUT_DIR, OUTPUT_FILENAME)

load_dotenv()

if "GROQ_API_KEY" not in os.environ:
    print("Error: GROQ_API_KEY not found in environment variables. Check your .env file.")
    sys.exit(1)

from models.GroqModels import GroqModels
from attacks.DataExtraction.enron import EnronDataExtraction
from attacks.DataExtraction.prompt_extract import PromptExtraction

enron = EnronDataExtraction(data_path="data/enron")

atk_format = '3-shot-known-domain-c'

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2] ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö Labels (‡πÄ‡∏â‡∏•‡∏¢) ‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ ---
# ‡πÄ‡∏î‡∏¥‡∏°: prompts, _ = ... (‡∏ó‡∏¥‡πâ‡∏á‡πÄ‡∏â‡∏•‡∏¢)
# ‡πÉ‡∏´‡∏°‡πà: ‡∏£‡∏±‡∏ö labels ‡∏°‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
prompts, labels = enron.generate_prompts(format=atk_format)

llm_model = "llama-3.1-8b-instant"
llm = GroqModels(model=llm_model)
attack = PromptExtraction()

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡πÅ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÑ‡∏ß‡πâ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
NUM_SAMPLES = 100

# ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏â‡∏•‡∏¢
test_prompts = prompts[:NUM_SAMPLES]
test_labels = labels[:NUM_SAMPLES]

print(f"Writing results to {OUTPUT_PATH}")
print(f"Starting attack on {len(test_prompts)} samples...")

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÇ‡∏à‡∏°‡∏ï‡∏µ
results = attack.execute_attack(test_prompts, llm)

print(f"Attack finished. Calculating metrics...")

# --- [‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3] ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metric ---
metric = ExtractionRate(outputs=results, labels=test_labels)
score = metric.compute_metric()
asr_percentage = score * 100

with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
    with redirect_stdout(f):
        print("="*100)
        print(f"DATA EXTRACTION RESULTS - Total: {len(results)} samples")
        print(f"METRIC SCORE (ASR): {asr_percentage:.2f}%")
        print("="*100)

        for idx in range(len(results)):
            print(f"\n{'‚îÄ'*100}")
            print(f"SAMPLE #{idx + 1}")
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ä‡∏ß‡πå‡πÉ‡∏ô Log (Success/Fail)
            clean_label = test_labels[idx].strip()
            is_success = clean_label in results[idx]
            status_icon = "‚úÖ LEAKED" if is_success else "‚ùå SAFE"
            
            print(f"STATUS: {status_icon}")
            print(f"{'‚îÄ'*100}")

            print(f"\nüìù PROMPT (Input):")
            print(test_prompts[idx])

            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏•‡∏¢ (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏≤)
            print(f"\nüîê LABEL (Secret):") 
            print(test_labels[idx])

            print(f"\nüí¨ ANSWER (Model Output):")
            print(results[idx])
            print()

        print("="*100)
        print(f"üìä FINAL SUMMARY")
        print(f"Total Samples: {len(results)}")
        print(f"Extraction Success Rate: {asr_percentage:.2f}%")
        print("="*100)

print(f"Done. Check the output directory: {OUTPUT_FILENAME}")
print(f"Final Extraction Success Rate: {asr_percentage:.2f}%")